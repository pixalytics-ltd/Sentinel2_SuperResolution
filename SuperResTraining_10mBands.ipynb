{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is built to develop and train the RCCN model for the 10 m bands (RGB and NIR).  Only blocks 2 and 3 will need to be edited by the user to provide the necessary inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3819,
     "status": "ok",
     "timestamp": 1635428061968,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "p7kNDltfZnld"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,MaxPool2D ,Convolution2D , Add, Dense , AveragePooling2D , UpSampling2D , Reshape , Flatten , Subtract , Concatenate, Cropping2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import backend as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to the location of the outputs by Pyrite (S2 imagery) and BeautySchoolDropout (PS imagery)\n",
    "# Change the directory to the location of the outputs by Pyrite (S2 imagery) and BeautySchoolDropout (PS imagery)\n",
    "homedir = r'/home/seadas/shared/marlisat/Training_Data'\n",
    "\n",
    "# Output folder (location of resulting preprocessed imagery -- recommend same location as S2 Pyrite output)\n",
    "out_folder = os.path.join(homedir, 'ESA-AO/output/')\n",
    "os.chdir(out_folder)\n",
    "\n",
    "# Output folder (location of resulting preprocessed imagery -- recommend same location as S2 Pyrite output)\n",
    "output_folder = os.path.join(homedir, 'ESA-AO/model/')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# Provide a folder with which to place the final model. \n",
    "# IMPORTANT: DO NOT put the same folder as the imagery.Temporary models will be stored there,\n",
    "# but then deleted. If you do not give a separate location for the complete models, they will also be deleted.\n",
    "# Ensure there is a '/' at the end.\n",
    "output_folder = \".../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11593,
     "status": "ok",
     "timestamp": 1635428106011,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "44EfYevlcbCM",
    "outputId": "8712900f-2745-40a6-e984-f31b3e3dca95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of downsampled Sentinel-2 10m array:  (4233, 2132, 5)\n",
      "Shape of downsampled Sentinel-2 20m array:  (2117, 1066, 7)\n",
      "Shape of downsampled Dove array:  (8449, 2182, 5)\n",
      "Shape of downsampled Dove orbit array:  (8449, 2182, 1)\n"
     ]
    }
   ],
   "source": [
    "# This date (or file identifier) should match what was used in BeautySchoolDropout\n",
    "date = 'Sep21_'\n",
    "\n",
    "# These two files correspond to the Pyrite output.  Choose the files with the EXACT SAME ratio (10to40, 20to80)\n",
    "s210m_40_fn = \"20210903_10to40_stack_norm.tif\" \n",
    "s220m_80_fn = \"20210903_20to80_stack_norm.tif\" \n",
    "\n",
    "# Ground truth. Choose the file that ends with \"10_stack_norm.tif\"\n",
    "s220m_20_fn = \"20210903_10_stack_norm.tif\" \n",
    "\n",
    "# If you gave the same identifier above as used in BeautySchoolDropout, this should run without further change\n",
    "dove10_fn = \"%sDove_10m_mosaic.tif\" %date # 4 bands + mask\n",
    "dove10orb_fn = \"%sDove_Orbits_10m.tif\" %date # orbit(strip number)\n",
    "\n",
    "s210m_40 = rasterio.open(s210m_40_fn).read().T\n",
    "s220m_80 = rasterio.open(s220m_80_fn).read().T\n",
    "dove10 = rasterio.open(dove10_fn).read().T\n",
    "dove10_orbits = rasterio.open(dove10orb_fn).read().T\n",
    "\n",
    "print('Shape of downsampled Sentinel-2 10m array: ', s210m_40.shape)\n",
    "print('Shape of downsampled Sentinel-2 20m array: ', s220m_80.shape)\n",
    "print('Shape of downsampled Dove array: ', dove10.shape)\n",
    "print('Shape of downsampled Dove orbit array: ', dove10_orbits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4180,
     "status": "ok",
     "timestamp": 1635428110187,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "-Po_bHlNdmNJ",
    "outputId": "b5781ad2-847a-4b67-a3c7-21defca63268"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16935, 8529, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s220m_20 = rasterio.open(s220m_20_fn).read().T\n",
    "s220m_20 = s220m_20[:, :, :-1] # Remove mask band for validation\n",
    "\n",
    "s220m_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8449, 2182, 13)\n",
      "(8449, 2182, 18)\n"
     ]
    }
   ],
   "source": [
    "encoded = ku.to_categorical(dove10_orbits, dtype='uint16')\n",
    "print(encoded.shape)\n",
    "\n",
    "dove10_with_orb = np.concatenate((dove10, encoded),axis=-1)\n",
    "print(dove10_with_orb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking image 1 (4233, 2132, 5)\n",
      "2101 more pixels in height\n",
      "Padded with zeros. New shape:  (4233, 4233, 5)\n",
      "Checking image 2 (2117, 1066, 7)\n",
      "1051 more pixels in height\n",
      "Padded with zeros. New shape:  (2117, 2117, 7)\n",
      "Checking image 3 (8449, 2182, 18)\n",
      "6267 more pixels in height\n",
      "Padded with zeros. New shape:  (8449, 8449, 18)\n",
      "Checking image 4 (16935, 8529, 4)\n",
      "8406 more pixels in height\n",
      "Padded with zeros. New shape:  (16935, 16935, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check for shape symetry and pad with zeros as needed\n",
    "model_images = [s210m_40, s220m_80, dove10_with_orb, s220m_20]\n",
    "\n",
    "for num, img in enumerate(model_images):   \n",
    "    print('Checking image {} {}'.format(num+1,img.shape))    \n",
    "    if img.shape[0] != img.shape[1]:\n",
    "#        if img.shape[0] - img.shape[1] <= 3 and img.shape[0] - img.shape[1] > 0:\n",
    "        if img.shape[0] - img.shape[1] > 0:\n",
    "            factor = img.shape[0] - img.shape[1]\n",
    "            print('%s more pixels in height' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, 0), (0, factor), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "#        elif img.shape[1] - img.shape[0] <= 3 and img.shape[1] - img.shape[0] > 0:\n",
    "        elif img.shape[1] - img.shape[0] > 0:\n",
    "            factor = img.shape[1] - img.shape[0]        \n",
    "            print('%s more pixels in width' %factor)\n",
    "            model_images[num] = np.pad(img, ((0, factor), (0, 0), (0, 0)))\n",
    "            print('Padded with zeros. New shape: ', model_images[num].shape)\n",
    "    else:\n",
    "        print('Shape is good: ', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing size compatibility. \n",
      "Padded with zeros. New shape:  (8453, 8453, 18)\n"
     ]
    }
   ],
   "source": [
    "# Check for compatibility among images\n",
    "mod_res_compare_size = model_images[0].shape[0]*4\n",
    "\n",
    "# Sometimes the above restriction causes problems.  The below line can be used to manual set the value.\n",
    "mod_res_compare_size = 8453\n",
    "\n",
    "if model_images[2].shape[0] < mod_res_compare_size:\n",
    "    print('Fixing size compatibility. ')\n",
    "    diff = abs(mod_res_compare_size - model_images[2].shape[0])\n",
    "    if diff < 5:\n",
    "        model_images[2] = np.pad(model_images[2], ((0, 0), (0, diff), (0, 0)))\n",
    "        model_images[2] = np.pad(model_images[2], ((0, diff), (0, 0), (0, 0)))\n",
    "        print('Padded with zeros. New shape: ', model_images[2].shape)\n",
    "    else:\n",
    "        print('Image size compatibility error: {} - {} should be < 5'.format(mod_res_compare_size, model_images[2].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1635428111214,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "SiuRB6K6eI5R"
   },
   "outputs": [],
   "source": [
    "def calc_patch(ii, jj, PATCH_SIZE_LR, dset_10, dset_20, dset_ps, dset_gt, ps_border):\n",
    "    upper_left_i = ii\n",
    "    upper_left_j = jj\n",
    "    crop_point_lr = [upper_left_i,\n",
    "                     upper_left_j,\n",
    "                     upper_left_i + PATCH_SIZE_LR[0],\n",
    "                     upper_left_j + PATCH_SIZE_LR[1]]\n",
    "    crop_point_hr = [p*2 for p in crop_point_lr]\n",
    "    crop_point_ps = [p*4 for p in crop_point_hr]\n",
    "    crop_point_gt = [p*4 for p in crop_point_hr]\n",
    "\n",
    "\n",
    "    label_20 = np.rollaxis(dset_gt[crop_point_gt[0]+ps_border:crop_point_gt[2]-ps_border, \n",
    "                                        crop_point_gt[1]+ps_border:crop_point_gt[3]-ps_border], 2)\n",
    "\n",
    "    image_20 = np.rollaxis(dset_20[crop_point_lr[0]:crop_point_lr[2],\n",
    "                     crop_point_lr[1]:crop_point_lr[3]], 2)\n",
    "\n",
    "    image_10 = np.rollaxis(dset_10[crop_point_hr[0]:crop_point_hr[2],\n",
    "                     crop_point_hr[1]:crop_point_hr[3]], 2)\n",
    "\n",
    "    #print(\"image_ps: {}\".format(crop_point_ps))\n",
    "    image_ps = np.rollaxis(dset_ps[crop_point_ps[0]:crop_point_ps[2],\n",
    "                     crop_point_ps[1]:crop_point_ps[3]], 2)\n",
    "    \n",
    "    return image_10, image_20, image_ps, label_20\n",
    "\n",
    "def get_test_patches(dset_10m, dset_20m, ps, dset_20gt, patchSize=24, border=4, ps_patch=96, ps_border=16):\n",
    "\n",
    "    PATCH_SIZE_HR = (patchSize, patchSize)\n",
    "    PATCH_SIZE_LR = [p//2 for p in PATCH_SIZE_HR]\n",
    "    BORDER_HR = border\n",
    "    BORDER_LR = BORDER_HR//2\n",
    "    PATCH_SIZE_PS = (ps_patch, ps_patch)\n",
    "    PATCH_SIZE_GT = (ps_patch-2*ps_border, ps_patch-2*ps_border)\n",
    "    print(\"Patch sizes {} {}\".format(PATCH_SIZE_HR,PATCH_SIZE_LR))\n",
    "    \n",
    "    # Mirror the data at the borders to have the same dimensions as the input\n",
    "    dset_10 = np.pad(dset_10m, ((BORDER_HR, BORDER_HR), (BORDER_HR, BORDER_HR), (0, 0)))\n",
    "    dset_20 = np.pad(dset_20m, ((BORDER_LR, BORDER_LR), (BORDER_LR, BORDER_LR), (0, 0)))\n",
    "    dset_ps = np.pad(ps, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))\n",
    "    dset_gt = np.pad(dset_20gt, ((ps_border, ps_border), (ps_border, ps_border), (0, 0)))\n",
    "    \n",
    "    BANDS10 = dset_10.shape[2]\n",
    "    BANDS20 = dset_20.shape[2]\n",
    "    BANDSps = dset_ps.shape[2]\n",
    "    BANDSgt = dset_gt.shape[2]\n",
    "    patchesAlongi = (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    patchesAlongj = (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    nr_patches = (patchesAlongi + 1) * (patchesAlongj + 1)\n",
    "    print(\"Number of patches: {} of size {} {}\".format(nr_patches, ps_patch, ps_patch))\n",
    "    max_patches = 1000\n",
    "    if nr_patches > max_patches:\n",
    "        skip = int((nr_patches/max_patches)/4.)\n",
    "        if skip < 1:\n",
    "            skip = 1\n",
    "        nr_patches = max_patches\n",
    "        print(\"Reduced number of patches to {} with skip {}\".format(nr_patches,skip))\n",
    "    else:\n",
    "        skip = 1\n",
    "\n",
    "    print(\"Setup arrays\")\n",
    "    label_20 = np.zeros((nr_patches, BANDSgt) + PATCH_SIZE_GT).astype(np.float32)   #initialize with PATCH_SIZE_PS but crop to PATCH_SIZE_GT\n",
    "    image_20 = np.zeros((nr_patches, BANDS20) + tuple(PATCH_SIZE_LR)).astype(np.float32)\n",
    "    image_10 = np.zeros((nr_patches, BANDS10) + PATCH_SIZE_HR).astype(np.float32)\n",
    "    image_ps = np.zeros((nr_patches, BANDSps) + PATCH_SIZE_PS).astype(np.float32)\n",
    "\n",
    "    range_i = np.arange(0, (dset_20.shape[0] - 2 * BORDER_LR) // (PATCH_SIZE_LR[0] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[0] - 2 * BORDER_LR)\n",
    "    range_j = np.arange(0, (dset_20.shape[1] - 2 * BORDER_LR) // (PATCH_SIZE_LR[1] - 2 * BORDER_LR)) * (\n",
    "        PATCH_SIZE_LR[1] - 2 * BORDER_LR)\n",
    "\n",
    "    if not (np.mod(dset_20.shape[0] - 2 * BORDER_LR, PATCH_SIZE_LR[0] - 2 * BORDER_LR) == 0):\n",
    "        range_i = np.append(range_i, (dset_20.shape[0] - PATCH_SIZE_LR[0]))\n",
    "    if not (np.mod(dset_20.shape[1] - 2 * BORDER_LR, PATCH_SIZE_LR[1] - 2 * BORDER_LR) == 0):\n",
    "        range_j = np.append(range_j, (dset_20.shape[1] - PATCH_SIZE_LR[1]))\n",
    "    print(\"Ranges[{},{}]: {} {} to {} {}\".format(len(range_i),len(range_j),np.nanmin(range_i), np.nanmax(range_i), np.nanmin(range_j), np.nanmax(range_j)))\n",
    "\n",
    "    pCount = 0\n",
    "    skip = 0\n",
    "    blank = 0\n",
    "    for ii in range_i.astype(int):\n",
    "        find = False\n",
    "        if ii%skip == 0:\n",
    "            for jj in range_j.astype(int):\n",
    "                if jj%skip == 0:\n",
    "                    try: \n",
    "                        image_10[pCount], image_20[pCount], image_ps[pCount], label_20[pCount] = calc_patch(ii, jj, PATCH_SIZE_LR, dset_10, \n",
    "                            dset_20, dset_ps, dset_gt, ps_border)\n",
    "                        #print(\"Loop {} {} image_ps {}\".format(ii,jj,np.nanmax(image_ps)))\n",
    "                        if np.nanmax(image_ps[pCount]) == 0 and skip > 1:\n",
    "                            blank += 1\n",
    "                            for incr in range(skip-1): \n",
    "                                image_10[pCount], image_20[pCount], image_ps[pCount], label_20[pCount] = calc_patch(ii+incr, jj+incr, PATCH_SIZE_LR, dset_10,\n",
    "                                    dset_20, dset_ps, dset_gt, ps_border)\n",
    "                                if np.nanmax(image_ps[pCount]) != 0:\n",
    "                                    blank -= 1\n",
    "                                    break\n",
    "                        pCount += 1\n",
    "                    except:\n",
    "                        #print(\"Skipping loop {} {}\".format(ii,jj))\n",
    "                        skip += 1\n",
    "                        \n",
    "                    if pCount == (max_patches - 1):\n",
    "                        find = True\n",
    "                        break\n",
    "            if find:\n",
    "                break\n",
    "                \n",
    "    print(\"Generated {} of {} patches with {} skipped and {} blank\".format(pCount, max_patches, skip, blank))\n",
    "\n",
    "    return image_10, image_20, image_ps, label_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4205,
     "status": "ok",
     "timestamp": 1635428115415,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "2DclF1KceMrS",
    "outputId": "265613c7-b5d8-4a1a-b1b7-5a71673e5751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch sizes (24, 24) [12, 12]\n",
      "Number of patches: 70225 of size 96 96\n",
      "Reduced number of patches to 1000 with skip 17\n",
      "Setup arrays\n",
      "Ranges[265,265]: 0 2109 to 0 2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6886/2194982026.py:85: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  if ii%skip == 0:\n",
      "/tmp/ipykernel_6886/2194982026.py:87: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  if jj%skip == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 157 of 1000 patches with 265 skipped and 16 blank\n"
     ]
    }
   ],
   "source": [
    "#print(\"dset_10m {} dset_20m {} ps {} dset_20gt {}\".format(model_images[0], model_images[1], model_images[2], model_images[3]))\n",
    "images_210, images_220, images_ps, label_20 = get_test_patches(model_images[0], model_images[1], model_images[2], model_images[3])\n",
    "#images_210, images_220, images_ps, label_20 = get_test_patches(s210m_40, s220m_80, dove10_with_orb, s220m_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1635428116386,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "s94kbHRwePXH",
    "outputId": "ce1b7b5e-ec98-48a9-8d2d-f36b76df9a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 24, 24, 5)\n",
      "(1000, 12, 12, 7)\n",
      "(1000, 96, 96, 18)\n",
      "(1000, 64, 64, 4)\n"
     ]
    }
   ],
   "source": [
    "images_210 = np.moveaxis(images_210, 1, 3)\n",
    "images_220 = np.moveaxis(images_220, 1, 3)\n",
    "images_ps = np.moveaxis(images_ps, 1, 3)\n",
    "label_20 = np.moveaxis(label_20, 1, 3)\n",
    "\n",
    "print(images_210.shape)\n",
    "print(images_220.shape)\n",
    "print(images_ps.shape)\n",
    "print(label_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2097,
     "status": "ok",
     "timestamp": 1635428119401,
     "user": {
      "displayName": "Amruta Vidwans",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11094605598230226609"
     },
     "user_tz": 300
    },
    "id": "eokpDUcOeaQ6"
   },
   "outputs": [],
   "source": [
    "images_210_tr1, images_210_test, images_220_tr1, images_220_test, images_ps_tr1, images_ps_test, label_20_tr1, label_20_test = train_test_split(images_210, images_220, images_ps, label_20, test_size=0.1, random_state=1)\n",
    "images_210_train, images_210_val, images_220_train, images_220_val, images_ps_train, images_ps_val, label_20_train, label_20_val = train_test_split(images_210_tr1, images_220_tr1, images_ps_tr1, label_20_tr1, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fzts5DOledmK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 96, 96, 18)\n",
      "(1000, 24, 24, 5)\n",
      "(1000, 12, 12, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 21:43:46.580331: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-07 21:43:46.580390: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2022-05-07 21:43:46.587617: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S220c shape is (None, 12, 12, 2240)\n",
      "S220s shape is (None, 96, 96, 35)\n",
      "S210c shape is (None, 24, 24, 400)\n",
      "S210s shape is (None, 96, 96, 25)\n",
      "all_inp shape is (None, 96, 96, 78)\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add/add:0', description=\"created by layer 'add'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_1/add:0', description=\"created by layer 'add_1'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_2/add:0', description=\"created by layer 'add_2'\")\n",
      "RDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='add_3/add:0', description=\"created by layer 'add_3'\")\n",
      "BofRDBlocks KerasTensor(type_spec=TensorSpec(shape=(None, 96, 96, 128), dtype=tf.float32, name=None), name='rdb_out/BiasAdd:0', description=\"created by layer 'rdb_out'\")\n",
      "Cropping KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 128), dtype=tf.float32, name=None), name='cropping2d/strided_slice:0', description=\"created by layer 'cropping2d'\")\n",
      "Output KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 4), dtype=tf.float32, name=None), name='conv2d_5/BiasAdd:0', description=\"created by layer 'conv2d_5'\")\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "batch_size1 = 32\n",
    "epochs1 = 100\n",
    "steps_per_epoch = 300\n",
    "tryout = 200\n",
    "gpu = 16 #check\n",
    "sample = 32\n",
    "mlt = 5\n",
    "scale = 4\n",
    "# patch_size = int(scale * 1024)\n",
    "patch_size = 96\n",
    "\n",
    "test_only = False\n",
    "\n",
    "chk = 1\n",
    "CHANNEL = 3\n",
    "\n",
    "def shLoss(y_true, y_pred, delta=2.0):\n",
    "    diff = y_true-y_pred\n",
    "    dsq = tf.keras.backend.square(delta)\n",
    "    return tf.keras.backend.mean( dsq * (tf.sqrt(1+ tf.square(diff)/dsq)-1), axis=-1)\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "\n",
    "\n",
    "def PSNRLoss(y_true, y_pred):\n",
    "        return 10* k.log(255**2 /(k.mean(k.square(y_pred - y_true))))\n",
    "\n",
    "\n",
    "class SRResnet:\n",
    "    def L1_loss(self , y_true , y_pred):\n",
    "        return k.mean(k.abs(y_true - y_pred))\n",
    "    \n",
    "    def RDBlocks(self, x, name, count = 6, filter_count=32, RDB_feat=64):\n",
    "        ## 6 layers of RDB block\n",
    "        ## this thing need to be in a damn loop for more customisability\n",
    "        li = [x]\n",
    "        pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu' , name = name+'_conv1')(x)\n",
    "\n",
    "        for i in range(2 , count+1):\n",
    "            li.append(pas)\n",
    "            out =  Concatenate(axis = -1)(li) # conctenated output self.channel_axis\n",
    "            pas = Convolution2D(filters=filter_count, kernel_size=(3,3), strides=(1, 1), padding='same' , activation='relu', name = name+'_conv'+str(i))(out)\n",
    "\n",
    "        li.append(pas)\n",
    "        out1 = Concatenate(axis = -1)(li) #self.channel_axis\n",
    "        feat = Convolution2D(filters=RDB_feat, kernel_size=(1,1), strides=(1, 1), padding='same',activation='relu' , name = name+'_Local_Conv')(out1)\n",
    "\n",
    "        feat = Add()([feat , x])\n",
    "        print(\"RDBlocks\",feat)\n",
    "        return feat\n",
    "        \n",
    "    def visualize(self):\n",
    "        plot_model(self.model, to_file='model.png' , show_shapes = True)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def Block_Of_RDBBlocks(self, inp, RDB_count=20, count=6, filter_count=32, RDB_feat=64, end_feat=64):\n",
    "        \n",
    "        pass1 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(inp)\n",
    "\n",
    "        pass2 = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(pass1)\n",
    "\n",
    "\n",
    "        RDB = self.RDBlocks(pass2 , 'RDB1', count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "        RDBlocks_list = [RDB,]\n",
    "        for i in range(2,RDB_count+1):\n",
    "            RDB = self.RDBlocks(RDB ,'RDB'+str(i), count=count, filter_count=filter_count, RDB_feat=RDB_feat)\n",
    "            RDBlocks_list.append(RDB)\n",
    "        out = Concatenate(axis = -1)(RDBlocks_list) #self.channel_axis\n",
    "        out = Convolution2D(filters=RDB_feat, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(out)\n",
    "        output = Add()([out, pass1])\n",
    "        output = Convolution2D(filters=end_feat, kernel_size=(3,3), strides=(1,1), padding='same', name=\"rdb_out\")(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def __init__(self, s10img, s20img, psimg, lr=0.00005, patch_size=32, RDB_count=4, count=2, filter_count=64, RDB_feat=128, end_feat=128, chk = -1, scale = 4):\n",
    "        self.channel_axis = 3\n",
    "        inp10 = Input(shape = (s10img.shape[1], s10img.shape[2], s10img.shape[3]))   # (24,24,4)\n",
    "        inp20 = Input(shape = (s20img.shape[1], s20img.shape[2], s20img.shape[3]))   # (12,12,6)\n",
    "        inpPS = Input(shape = (psimg.shape[1], psimg.shape[2], psimg.shape[3]))   # (96,96,9)\n",
    "        print(psimg.shape)\n",
    "        print(s10img.shape)\n",
    "        print(s20img.shape)\n",
    "#         print(psorb.shape)\n",
    "#         ps = tf.keras.layers.Concatenate(axis=2)([psimg, psorb])\n",
    "\n",
    "        Subpixel_scale8 = Lambda(lambda x:tf.nn.depth_to_space(x,8))\n",
    "        Subpixel_scale4 = Lambda(lambda x:tf.nn.depth_to_space(x,4))\n",
    "        \n",
    "        s220c = Convolution2D(filters = (s20img.shape[3])*8*8*mlt, kernel_size=1, strides=1, padding='valid')(inp20)\n",
    "        print(\"S220c shape is\", s220c.shape)\n",
    "        s220s = Subpixel_scale8(inputs=s220c)\n",
    "        print(\"S220s shape is\", s220s.shape)\n",
    "        m20 = Model(inputs=inp20, outputs=s220s)\n",
    "        s210c = Convolution2D(filters = (s10img.shape[3])*4*4*mlt, kernel_size=1, strides=1, padding='valid')(inp10)\n",
    "        print(\"S210c shape is\", s210c.shape)\n",
    "        s210s = Subpixel_scale4(inputs=s210c)\n",
    "        print(\"S210s shape is\", s210s.shape)\n",
    "        m10 = Model(inputs=inp10, outputs=s210s)\n",
    "        \n",
    "        all_inp = Concatenate(axis=-1)([m10.output, m20.output, inpPS])\n",
    "        print(\"all_inp shape is\", all_inp.shape)\n",
    "        allb = self.Block_Of_RDBBlocks(all_inp, RDB_count, count, filter_count, RDB_feat, end_feat)\n",
    "        print(\"BofRDBlocks\",allb)\n",
    "        allm = Cropping2D(cropping=16)(allb)\n",
    "        print(\"Cropping\",allm)\n",
    "        allrc = Convolution2D(filters = 4, kernel_size = 1, strides = 1, padding = \"valid\", activation = None)(allm)\n",
    "        \n",
    "        print(\"Output\", allrc)\n",
    "        model = Model(inputs=[m10.input, m20.input, inpPS], outputs = allrc)\n",
    "#         print([n.input_tensors.name for n in model.get_layer('A_3').inbound_nodes])\n",
    "        adam = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, decay=0, amsgrad=False)\n",
    "\n",
    "        model.compile(loss=shLoss, optimizer='adam' , metrics=['mae'])\n",
    "\n",
    "        if chk >=0 :\n",
    "            print(\"loading existing weights !!!\")\n",
    "            model.load_weights('final.h5')\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "    def fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_data, steps_per_epoch):   \n",
    "        hist = self.model.fit(x, y, batch_size, epochs, verbose, callbacks, validation_data=validation_data, steps_per_epoch=steps_per_epoch)\n",
    "        return hist.history\n",
    "\n",
    "\n",
    "chk = -1\n",
    "net = SRResnet(images_210, images_220, images_ps, lr = lr ,scale = scale , chk = chk)\n",
    "net.visualize()\n",
    "# net.get_model().summary()\n",
    "\n",
    "my_callbacks =[\n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath='model4x.{epoch:02d}-{val_loss:.2f}',\n",
    "              monitor = \"loss\",\n",
    "              verbose = 1,\n",
    "              save_best_only = True,\n",
    "              save_freq = \"epoch\"\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "              monitor = \"loss\",\n",
    "              factor = 0.9,\n",
    "              patience = 20,\n",
    "              verbose = 1,\n",
    "              min_lr = 0.0001 / 10\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "              monitor = \"loss\",\n",
    "              min_delta = 2,\n",
    "              patience = 200,\n",
    "              verbose = 1,\n",
    "              baseline = None,\n",
    "              restore_best_weights = False\n",
    "            ),\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 24, 24, 5)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 12, 12, 7)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 24, 24, 400)  2400        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 12, 12, 2240  17920       ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 96, 96, 25)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 96, 96, 35)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 96, 96, 18)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 96, 96, 78)   0           ['lambda_1[0][0]',               \n",
      "                                                                  'lambda[0][0]',                 \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 96, 96, 128)  89984       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 96, 96, 128)  147584      ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " RDB1_conv1 (Conv2D)            (None, 96, 96, 64)   73792       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 96, 96, 192)  0           ['conv2d_3[0][0]',               \n",
      "                                                                  'RDB1_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " RDB1_conv2 (Conv2D)            (None, 96, 96, 64)   110656      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 96, 96, 256)  0           ['conv2d_3[0][0]',               \n",
      "                                                                  'RDB1_conv1[0][0]',             \n",
      "                                                                  'RDB1_conv2[0][0]']             \n",
      "                                                                                                  \n",
      " RDB1_Local_Conv (Conv2D)       (None, 96, 96, 128)  32896       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 96, 96, 128)  0           ['RDB1_Local_Conv[0][0]',        \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " RDB2_conv1 (Conv2D)            (None, 96, 96, 64)   73792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 96, 96, 192)  0           ['add[0][0]',                    \n",
      "                                                                  'RDB2_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " RDB2_conv2 (Conv2D)            (None, 96, 96, 64)   110656      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 96, 96, 256)  0           ['add[0][0]',                    \n",
      "                                                                  'RDB2_conv1[0][0]',             \n",
      "                                                                  'RDB2_conv2[0][0]']             \n",
      "                                                                                                  \n",
      " RDB2_Local_Conv (Conv2D)       (None, 96, 96, 128)  32896       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 96, 96, 128)  0           ['RDB2_Local_Conv[0][0]',        \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " RDB3_conv1 (Conv2D)            (None, 96, 96, 64)   73792       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 96, 96, 192)  0           ['add_1[0][0]',                  \n",
      "                                                                  'RDB3_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " RDB3_conv2 (Conv2D)            (None, 96, 96, 64)   110656      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 96, 96, 256)  0           ['add_1[0][0]',                  \n",
      "                                                                  'RDB3_conv1[0][0]',             \n",
      "                                                                  'RDB3_conv2[0][0]']             \n",
      "                                                                                                  \n",
      " RDB3_Local_Conv (Conv2D)       (None, 96, 96, 128)  32896       ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 96, 96, 128)  0           ['RDB3_Local_Conv[0][0]',        \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " RDB4_conv1 (Conv2D)            (None, 96, 96, 64)   73792       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 96, 96, 192)  0           ['add_2[0][0]',                  \n",
      "                                                                  'RDB4_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " RDB4_conv2 (Conv2D)            (None, 96, 96, 64)   110656      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 96, 96, 256)  0           ['add_2[0][0]',                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'RDB4_conv1[0][0]',             \n",
      "                                                                  'RDB4_conv2[0][0]']             \n",
      "                                                                                                  \n",
      " RDB4_Local_Conv (Conv2D)       (None, 96, 96, 128)  32896       ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 96, 96, 128)  0           ['RDB4_Local_Conv[0][0]',        \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 96, 96, 512)  0           ['add[0][0]',                    \n",
      "                                                                  'add_1[0][0]',                  \n",
      "                                                                  'add_2[0][0]',                  \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 96, 96, 128)  589952      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 96, 96, 128)  0           ['conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " rdb_out (Conv2D)               (None, 96, 96, 128)  147584      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 64, 64, 128)  0           ['rdb_out[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 4)    516         ['cropping2d[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,865,316\n",
      "Trainable params: 1,865,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7ed42ddd6f04227c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7ed42ddd6f04227c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 21:43:54.223522: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 537477120 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model10 = net.get_model()\n",
    "model10.summary()\n",
    "%tensorboard --logdir logs/\n",
    "model10.fit(x=[images_210_train, images_220_train, images_ps_train], y=label_20_train, batch_size=batch_size1, epochs=epochs1, verbose=1, callbacks=my_callbacks, validation_data=([images_210_val, images_220_val, images_ps_val], label_20_val))#, validation_steps = 3) #steps_per_epoch=steps_per_epoch\n",
    "\n",
    "model10.save(output_folder + date + 'trained_10m_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSJOnNzQm55S"
   },
   "outputs": [],
   "source": [
    "# Remove old models and log files\n",
    "files_list = os.listdir()\n",
    "\n",
    "for file in files_list:\n",
    "    if 'model' in file:\n",
    "        shutil.rmtree(file)\n",
    "        \n",
    "for file in files_list:\n",
    "    if 'logs' in file:\n",
    "        shutil.rmtree(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SuperResTraining4x.ipynb",
   "provenance": [
    {
     "file_id": "1SLGUAH7f6cTH7WMEFnOSuL3LxtMlHVdJ",
     "timestamp": 1634931909576
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
